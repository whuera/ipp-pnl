# -*- coding: utf-8 -*-
"""William_Huera_M4_E1_Procesamiento_Natural_Del_Lenguaje.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18_TUwYgkVZOGJcoxDu5S7B3JUkYFZ4ym

## Caso de an√°lisis:
Al d√≠a siguiente, presentamos los resultados anteriores al equipo y obtenemos el VoBo para continuar. Efectivamente, lo obtenido hasta el momento hace sentido, y lo importante es que ya se cuenta con un corpus de comentarios limpio y se tiene un vocabulario resumido. Alguien del equipo expresa que ya se puede aplicar, entonces, un modelo para clasificaci√≥n, por lo que -con todo la raz√≥n- argumentamos que primero se debe obtener una representaci√≥n vectorial del corpus, y justamente es lo que se pondr√° en foco a continuaci√≥n.

## Consignas

1. Representaci√≥n vectorial: en esta parte, se debe aplicar un modelo de representaci√≥n vectorial. Se recomienda el uso de TfidfVectorizer por sobre una representaci√≥n BoW debido a que facilita la inclusi√≥n de los emojis, tal como se expone en el siguiente ejemplo:

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(token_pattern='[^\s]+')
tfidf_X_train = tfidf.fit_transform(X_train)

El modelo para la vectorizaci√≥n debe ajustarse primero con los datos X de entrenamiento y, posteriormente, realizar la transformaci√≥n con los datos X de testeo:
tfidf_X_test = tfidf.transform(X_test)

Resoluci√≥n:
mantenemos el c√≥digo del API2, para mantener los datos calculados

1) Importaci√≥n de librerias
"""

import pandas as pd
import numpy as np
import re
import nltk
from nltk.tokenize import RegexpTokenizer
from nltk.stem import WordNetLemmatizer, PorterStemmer
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

nltk.download('wordnet')
nltk.download('stopwords')

"""2) limpieza y tokenizaci√≥n"""

import re

def limpiar_tokenizar(texto):
  texto = texto.lower()
  tokenizer = RegexpTokenizer(r'[^\s^,^.^;]+')
  tokens = tokenizer.tokenize(texto)
  return tokens
  texto = 'vi viene √∫ltima . fff , ‚ù§ ü•∞ :)'
  tokens = limpiar_tokenizar(texto)
  print(tokens)

"""b. lemantizaci√≥n y stemming"""

from nltk.stem import WordNetLemmatizer, PorterStemmer

# funci√≥n para lemantizar
def lematizar(tokens):
  lemmatizer = WordNetLemmatizer()
  lemas = [lemmatizer.lemmatize(token) for token in tokens]
  return lemas

# funci√≥n para stemming
def stemming(tokens):
  stemmer = PorterStemmer()
  raices = [stemmer.stem(token) for token in tokens]
  return raices

"""ejemplos:"""

data ={
    'texto':[
        "Este es un buen ejemplo.",
        "Este es un mal ejemplo.",
        "Este es un ejemplo informativo.",
        "comentario adicional",
        "comentario malo",
        "comentario bueno"
    ],
    'target':['bueno', 'malo', 'info', 'adicional', 'malo', 'bueno']
}
df = pd.DataFrame(data)
df['tokens'] = df['texto'].apply(limpiar_tokenizar)
df['lemas'] = df['tokens'].apply(lematizar)
df['raices'] = df['tokens'].apply(stemming)

print(df[['lemas','texto','tokens', 'raices']])

"""3) split de la muestra"""

train, test = train_test_split(df, test_size=0.2, random_state=42)
print("Entrenamiento:")
print(train)
print("Prueba:")
print(test)

"""4) target"""

import matplotlib.pyplot as plt
import seaborn as sns

train['set'] = 'train'
test['set'] = 'test'
df_all = pd.concat([train, test])

# gr√°fica
plt.figure(figsize=(10, 6))
sns.countplot(x='target', hue='set', data=df_all)
plt.title('Distribuci√≥n del target seg√∫n muestra train y test')
plt.xlabel('Target')
plt.ylabel('Cantidad')
plt.legend(title='Set')
plt.show()

"""## Desarrollo API3 - NPL

importamos librerias
"""

from sklearn.feature_extraction.text import TfidfVectorizer

"""Definimos las variables para entrenamiento"""

X_train = train['texto']
X_test = test['texto']
y_train = train['target']
y_test = test['target']

"""Generamos el modelo tfidfVectorizer, que aplica el token_pattter para incluir los emojis"""

tfidf = TfidfVectorizer(token_pattern='[^\s]+')

"""Se ajusta el modelo con los datos de entrenamiento"""

tfidf_X_train = tfidf.fit_transform(X_train)

"""transformar datos"""

tfidf_X_test = tfidf.transform(X_test)

"""Mostramos las matrices resultantes"""

print("Dimensiones del conjunto de entrenamiento: ", tfidf_X_train.shape)
print("Dimensiones del conjunto de prueba: ", tfidf_X_test.shape)

"""Obtener las caracteristicas (tokens)"""

feature_names = tfidf.get_feature_names_out()

"""convertir la matriz tfidf_X_train en dataframe"""

tfidf_df = pd.DataFrame(tfidf_X_train.toarray(), columns=feature_names)

"""convertir tfidf_X_test en dataframe"""

tfidf_df_test = pd.DataFrame(tfidf_X_test.toarray(), columns=feature_names)

"""Visualizar dataframe"""

print("Matriz tfidf_X_train")
print(tfidf_df.head())

print("Matriz tfidf_X_test")
print(tfidf_df_test.head())

"""## Desarrollo API 4

## Caso de an√°lisis:
Una vez lograda la representaci√≥n vectorial del texto, se argumenta que ahora s√≠ se ha conseguido una data estructurada gracias al preprocesamiento de texto, y que este resultado, a su vez, puede ser INPUT para un modelo. Una vez m√°s, alguien del equipo expresa que quiere aplicar una regresi√≥n lineal, a lo que contestamos que no se puede porque el target de este problema no es num√©rico, y m√°s bien hay que ponerse a trabajar en un modelo supervisado para clasificaci√≥n. ¬øQu√© modelos se aplicar√°n?

## Consignas

Modelo machine learning. Aplique un modelo machine learning -de los que Ud. ya conoce- para el problema de clasificaci√≥n.
Se pueden utilizar los modelos de aprendizaje supervisado, tales como: random forest, support vector machine, vecinos m√°s cercanos (KNN), regresi√≥n log√≠stica, o Na√Øve Bayes. El modelo debe ajustarse con los vectores de la muestra de entrenamiento. Es importante que se considere que el target es multinomial y no binomial (sobre todo en la regresi√≥n log√≠stica).

Evaluaci√≥n del modelo. Seg√∫n las predicciones de la muestra de testeo, realice la evaluaci√≥n del modelo. Para ello, calcule los √≠ndices de desempe√±o como acuracidad, recall y precisi√≥n. Interprete los resultados y exponga sus conclusiones.
"""

from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
model=GaussianNB()
model.fit(tfidf_X_train.toarray(),y_train)

from sklearn.metrics import accuracy_score, recall_score, precision_score
y_test_pred = model.predict(tfidf_X_test.toarray())
y_train_pred = model.predict(tfidf_X_train.toarray())
print("Accuracy de entrenamiento: {0:0.4f}".format(accuracy_score(y_train, y_train_pred)))
print("Accuracy de prueba: {0:0.4f}".format(accuracy_score(y_test, y_test_pred)))

print("Precision de entrenamiento (train): {0:0.4f}".format(precision_score(y_train, y_train_pred, average='weighted')))
print("Precision de prueba (test): {0:0.4f}".format(precision_score(y_test, y_test_pred, average='weighted')))

print("Recall de entrenamiento (train): {0:0.4f}".format(recall_score(y_train, y_train_pred, average='weighted')))
print("Recall de prueba (test): {0:0.4f}".format(recall_score(y_test, y_test_pred, average='weighted')))